{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "## headings\n",
    "\"\"\"\n",
    "made by weiyw @ 2019-04-04\n",
    "made to use both vz and vx components\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import struct\n",
    "import argparse\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D#Convolution2D\n",
    "# from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import (Input, Activation, merge, Dense, Reshape)\n",
    "import metrics as metrics\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # 使用编号为1，2号的GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1 # 每个GPU现存上届控制在60%以内\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters():\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        \n",
    "    def initialize(self, parser):\n",
    "        parser.add_argument('-data_path', required=True, help='path of readin data')\n",
    "        parser.add_argument('-out_name', required=True, help='the name of output model')\n",
    "        parser.add_argument('-nt', type=int, default=4000, help='time steps')\n",
    "        parser.add_argument('-nr', type=int, default=400, help='receivers')\n",
    "        parser.add_argument('-ns', type=int, default=51, help='time steps')\n",
    "        parser.add_argument('-batch_size', type=int, default=2, help='batch size')\n",
    "        parser.add_argument('-nph', type=int, default=2, help='how many phase in one data, 2 for vx vz; 1 for vz')\n",
    "        parser.add_argument('-epoch', type=int, default=100, help='epoch')\n",
    "        parser.add_argument('-ratio', type=float, default=0.5, help='the ratio of training data in the whole dataset')\n",
    "        self.initialized = True\n",
    "        return parser\n",
    "    \n",
    "    def gather_options(self):\n",
    "        if not self.initialized:\n",
    "            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "            parser = self.initialize(parser)\n",
    "        opt, _ = parser.parse_known_args()\n",
    "        self.parser = parser\n",
    "        return parser.parse_args()\n",
    "    \n",
    "    def parse(self):\n",
    "        opt = self.gather_options()\n",
    "        self.opt = opt\n",
    "        return self.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_min_nonzero_value(data_in, init_min = 1):\n",
    "    min_value = init_min\n",
    "    for bb in data_in:\n",
    "        for aa in bb:\n",
    "            if abs(aa) < min_value and aa != 0:\n",
    "                min_value = abs(aa)\n",
    "    return min_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_bindata(data_path, data_index, data_phase, nt, nr):\n",
    "    # data_index start from 1\n",
    "    model_num = int( ( int(data_index) - 1 ) / 51) + 1\n",
    "    source_num = ( int(data_index) - 1 ) % 51 + 1\n",
    "    data_name = data_path + \"/model\" + str(model_num) + \"source\" + str(source_num) + data_phase + \".bin\"\n",
    "\n",
    "    out_data = np.empty((nt,nr))\n",
    "    FA = open(data_name, \"rb\")\n",
    "    FA.seek(3232,0)\n",
    "    for tt in range(nt):\n",
    "        for rr in range(nr):\n",
    "            data = FA.read(4)\n",
    "            data_float = struct.unpack(\"f\", data)[0]\n",
    "            out_data[tt][rr] = data_float\n",
    "    return out_data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, data_path, nt, nr, nph):\n",
    "        self.data_path = data_path\n",
    "        self.nt = nt\n",
    "        self.nr = nr\n",
    "        self.nph = nph\n",
    "    \n",
    "    def readin_bin_data(self, data_name):\n",
    "        out_data = np.empty((self.nt, self.nr))\n",
    "        FA = open(data_name, \"rb\")\n",
    "        FA.seek(3232,0)\n",
    "        for tt in range(self.nt):\n",
    "            for rr in range(self.nr):\n",
    "                data = FA.read(4)\n",
    "                data_float = struct.unpack(\"f\", data)[0]\n",
    "                out_data[tt][rr] = data_float\n",
    "        return out_data      \n",
    "    \n",
    "    def load_batch(self, batch_size=1, is_testing=False, ratio=0.5):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        path = glob('%s/vz/*' % self.data_path)\n",
    "       \n",
    "        self.n_batches = int( len(path) / batch_size * ratio )\n",
    "        for i in range(self.n_batches):\n",
    "            x_data = np.empty((batch_size, self.nt, self.nr, self.nph)) ## b-4000-300-2, vz, vx\n",
    "            y_data = np.empty((batch_size, self.nt, self.nr, self.nph)) ## b-4000-300-2, div, curl\n",
    "            for data_index_local in range(batch_size): ## 0 ~ batchsize-1\n",
    "                data_index = i * batch_size + data_index_local + 1\n",
    "                model_num = int( ( int(data_index) - 1 ) / 51) + 1\n",
    "                source_num = ( int(data_index) - 1 ) % 51 + 1\n",
    "                if self.nph == 2:\n",
    "                    for data_phase in ['vz', 'vx']:\n",
    "                        p_flag = int(data_phase == 'vx')\n",
    "                        data_name = self.data_path + \"/\" + data_phase + \\\n",
    "                        \"/model\" + str(model_num) + \"source\" + str(source_num) + data_phase + \".bin\"\n",
    "                        x_data[data_index_local, :, :, p_flag] = self.readin_bin_data(data_name)\n",
    "                    for data_phase in ['div', 'curl']:\n",
    "                        p_flag = int(data_phase == 'curl')\n",
    "                        data_name = self.data_path + \"/\" + data_phase + \\\n",
    "                        \"/model\" + str(model_num) + \"source\" + str(source_num) + data_phase + \".bin\"\n",
    "                        y_data[data_index_local, :, :, p_flag] = self.readin_bin_data(data_name)\n",
    "                if self.nph == 1:\n",
    "                    data_phase = 'vz'\n",
    "                    data_name = self.data_path + \"/\" + data_phase + \\\n",
    "                    \"/model\" + str(model_num) + \"source\" + str(source_num) + data_phase + \".bin\"\n",
    "                    x_data[data_index_local, :, :, 0] = self.readin_bin_data(data_name)\n",
    "                    data_phase = 'div'\n",
    "                    data_name = self.data_path + \"/\" + data_phase + \\\n",
    "                    \"/model\" + str(model_num) + \"source\" + str(source_num) + data_phase + \".bin\"\n",
    "                    y_data[data_index_local, :, :, 0] = self.readin_bin_data(data_name)                    \n",
    "                yield x_data, y_data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def simpleNet(nt, nr, nph):\n",
    "    x_input = Input( shape=( nt, nr, nph) )##one_piece\n",
    "    conv1 = Conv2D(\n",
    "        nb_filter=64, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(x_input)\n",
    "    conv1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1)\n",
    "    conv2 = Conv2D(\n",
    "        nb_filter=2, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(conv1)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=conv2)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/media/wywdisk/VSPdata/data/haveinvx/layer2_haveinvx\"\n",
    "\n",
    "# nt = 4000     # time step\n",
    "# nr = 400      # receiver\n",
    "# ns = 51       # shot\n",
    "# nmodel = 2    # batch\n",
    "# nph = 2\n",
    "\n",
    "# ## training parameters\n",
    "# TPepoches = 4\n",
    "# TPbatch_size = 4\n",
    "\n",
    "## setup\n",
    "opt = parameters().parse()\n",
    "model = simpleNet(opt.nt, opt.nr, opt.nph)\n",
    "model.summary()\n",
    "my_data_loader = Dataloader(opt.data_path, opt.nt, opt.nr, opt.nph)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saveing parameters\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "filepath = os.path.join(save_dir,'{}.best.h5'.format(opt.out_name))\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=0, save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "callbacks = [checkpoint]#, lr_reducer, lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "log = model.fit_generator(my_data_loader.load_batch(batch_size=opt.batch_size, is_testing=False, ratio=opt.ratio),\\\n",
    "              steps_per_epoch=opt.batch_size, epochs=opt.epoch, verbose=1, callbacks=callbacks, validation_data=None, \\\n",
    "              validation_steps=None, class_weight=None, max_queue_size=10, \\\n",
    "              workers=1, use_multiprocessing=False, shuffle=False, initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving last model\n",
    "json_string = model.to_json()\n",
    "open('model_json', 'w').write(json_string)\n",
    "model.save_weights(os.path.join( save_dir, '{}.final.best.h5'.format(opt.out_name)), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %hist -f simpleNet_training_rawdata_vxvz.py"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (tf-keras)",
   "language": "python",
   "name": "tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## headings\n",
    "\"\"\"\n",
    "made by weiyw @ 2019-04-08\n",
    "made to test training results, using both three components in segy data\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import struct\n",
    "import segyio\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import (Input, Activation, merge, Dense, Reshape)\n",
    "import metrics as metrics\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, data_path, nt, nr, nph):\n",
    "        self.data_path = data_path\n",
    "        self.nt = nt\n",
    "        self.nr = nr\n",
    "        self.nph = nph\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False, ratio=0.5):        \n",
    "        self.n_batches = int( 151 / batch_size * ratio ) #int( len(path) / batch_size * ratio )\n",
    "        x_data = np.empty((batch_size, self.nt, self.nr, self.nph)) ## b-2001-467-4, acc\n",
    "        y_data = np.empty((batch_size, self.nt, self.nr, 1)) ## b-2001-467-1, div, curl\n",
    "        i = 0\n",
    "        with segyio.open(self.data_path,'r',ignore_geometry=True) as segyfile: \n",
    "            segyfile.mmap()\n",
    "            while True:\n",
    "#             for i in range(self.n_batches):\n",
    "                if (i + 1) * batch_size > 151 * ratio:\n",
    "                    i = 0\n",
    "#                     break\n",
    "                for batch_i in range(batch_size):\n",
    "                    for nr_i in range(self.nr):\n",
    "#                     with segyio.open(self.data_path,'r',ignore_geometry=True) as segyfile:      \n",
    "                        y_data[batch_i,:,nr_i,0] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 0]\n",
    "                        x_data[batch_i,:,nr_i,0] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 1]\n",
    "                        x_data[batch_i,:,nr_i,1] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 2]\n",
    "                        x_data[batch_i,:,nr_i,2] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 3]     \n",
    "                data_process()\n",
    "                yield x_data, y_data\n",
    "                i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def simpleNet(nt, nr, nph):\n",
    "    x_input = Input( shape=( nt, nr, nph) )##one_piece\n",
    "#     conv1 = Conv2D(\n",
    "#         nb_filter=64, nb_row=3, nb_col=3, padding=\"same\", data_format=\"channels_last\")(x_input)\n",
    "    conv1 = Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding='same', data_format='channels_last', \n",
    "                   dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(x_input)\n",
    "    conv1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1)\n",
    "#     conv1_1 = Conv2D(\n",
    "#         nb_filter=128, nb_row=3, nb_col=3, padding=\"same\", data_format=\"channels_last\")(conv1)\n",
    "    conv1_1 = Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='same', data_format='channels_last', \n",
    "                   dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(conv1)\n",
    "    conv1_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_1)\n",
    "    \n",
    "    conv1_2 = Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='same', data_format='channels_last', \n",
    "                   dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(conv1_1)\n",
    "#     conv1_2 = Conv2D(\n",
    "#         nb_filter=128, nb_row=3, nb_col=3, padding=\"same\", data_format=\"channels_last\")(conv1_1)\n",
    "    conv1_2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_2)\n",
    "#     conv1_3 = Conv2D(\n",
    "#         nb_filter=128, nb_row=3, nb_col=3, padding=\"same\", data_format=\"channels_last\")(conv1_2)\n",
    "    conv1_3 = Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='same', data_format='channels_last', \n",
    "                   dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(conv1_2)   \n",
    "    conv1_3 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_3)\n",
    "    \n",
    "    conv2 = Conv2D(filters=1, kernel_size=(3,3), strides=(1, 1), padding='same', data_format='channels_last', \n",
    "                   dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(conv1_3)\n",
    "\n",
    "\n",
    "#     conv2 = Conv2D(\n",
    "#         nb_filter=1, nb_row=3, nb_col=3, padding=\"same\", data_format=\"channels_last\")(conv1_3)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=conv2)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/media/wywdisk/VSPdata/data/haveinvx/layer2_haveinvx\"\n",
    "# data_path = '/media/wywdisk/VSPdata/data/realData/SEAM_I_Walkaway_VSP/SEAM_Well1VSP_Shots23900.sgy'\n",
    "data_path = '/home/wyw/data/SEAM_I_walkaway_vsp_s23900/SEAM_Well1VSP_Shots23900.sgy'\n",
    "# out_name = 'simpleNet_training_rawdata_3c_segy-20190407-22.final'\n",
    "out_name = 'simpleNet_training_rawdata_3c_segy-20190408-16.final'\n",
    "\n",
    "nt = 2001     # time step\n",
    "nr = 467      # receiver\n",
    "ns = 151       # shot\n",
    "nmodel = 1    # batch\n",
    "nph = 3\n",
    "\n",
    "TPepoches = 1\n",
    "TPbatch_size = 1\n",
    "\n",
    "model = simpleNet(nt, nr, nph)\n",
    "my_data_loader = Dataloader(data_path, nt, nr, nph)\n",
    "\n",
    "save_dir = '/home/wyw/workspace/keras-run/vsp_sep_3c/saved_models' #os.path.join(os.getcwd(), 'saved_models')\n",
    "model.load_weights(os.path.join(save_dir, '{}.best.h5'.format(out_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_shot = 0\n",
    "x_test = np.empty((1, nt, nr, nph)) ## b-2001-467-4, acc\n",
    "y_test = np.empty((1, nt, nr, 1)) ## b-2001-467-1, div, curl\n",
    "with segyio.open(data_path,'r',ignore_geometry=True) as segyfile:\n",
    "    segyfile.mmap()\n",
    "    for nr_i in range(nr):\n",
    "        y_test[0,:,nr_i,0] = segyfile.trace[i_shot*4*nr + nr_i * 4 + 0]\n",
    "        x_test[0,:,nr_i,0] = segyfile.trace[i_shot*4*nr + nr_i * 4 + 1]\n",
    "        x_test[0,:,nr_i,1] = segyfile.trace[i_shot*4*nr + nr_i * 4 + 2]\n",
    "        x_test[0,:,nr_i,2] = segyfile.trace[i_shot*4*nr + nr_i * 4 + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## prdiction\n",
    "# # y_predict = model.predict(x_test, batch_size=None, steps=1, verbose = 1)\n",
    "\n",
    "# predict = model.predict_generator(my_data_loader.load_batch(batch_size=TPbatch_size, is_testing=True, ratio=0.02),\\\n",
    "#                                   steps=1, max_queue_size=10, \\\n",
    "#                                   workers=1, use_multiprocessing=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test, batch_size=None, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for predicted data\n",
    "a1 = y_predict\n",
    "print(\"Information of a1 :\")\n",
    "print(\"The shape of a1   :\",a1.shape)\n",
    "print(\"The range        : \", [a1.min(),a1.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for predicted data\n",
    "a1 = y_test\n",
    "print(\"Information of a1 :\")\n",
    "print(\"The shape of a1   :\",a1.shape)\n",
    "print(\"The range        : \", [a1.min(),a1.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot y_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "lines = 1\n",
    "cols = 2\n",
    "forts = 12\n",
    "ss1 = 300\n",
    "ss2 = 400\n",
    "\n",
    "x_libs = [0,1000,2750,1750+2750,2*1750+2750,8000]#[0,0, 500, 1000, 1500, 2000]#np.linspace(0,1500,4)#[0, 500, 1000, 1500]\n",
    "y_libs = 8 * np.linspace(0,2,9)#[0,0.4, 0.8, 1.2, 1.6, 2]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10, 4), sharey=True)\n",
    "\n",
    "# obj = 'y_predict'\n",
    "# im = plt.imshow(eval(obj)[0,:,:,1], extent=[0, 512, 512,0])\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# ax1 = plt.subplot(131)\n",
    "ax1 = plt.subplot(lines,cols,1)\n",
    "obj = 'y_predict'\n",
    "target_data = eval(obj)[0,:,:,0]\n",
    "value_limit=np.max( target_data ) *0.05 #/ 10\n",
    "# print(obj, \": \", eval(obj).shape, \"\\t\", [eval(obj).min(), eval(obj).max()] )\n",
    "im = plt.imshow(target_data, extent=[0, ss1, ss2,0],vmin=-value_limit, vmax=value_limit, cmap=\"gray\")\n",
    "plt.colorbar(im)\n",
    "# plt.title(\"The elastic z component of VSP data\", fontsize=forts);\n",
    "plt.title(\"predicted P-wave\", fontsize=forts);\n",
    "plt.xlabel('depth(m)', fontsize=forts);\n",
    "plt.ylabel('time(s)', fontsize=forts);\n",
    "# ax1 = fig.add_subplot(131)\n",
    "ax1.xaxis.set_major_locator(MultipleLocator(75))\n",
    "ax1.xaxis.set(ticklabels=x_libs)#[0,300,600, 900, 1200, 1500]);\n",
    "ax1.yaxis.set(ticklabels=y_libs)#[0,0.4, 0.8, 1.2, 1.6, 2]);\n",
    "plt.setp(ax1.get_xticklabels(), fontsize=10);\n",
    "# plt.tight_layout()\n",
    "\n",
    "# ax1 = plt.subplot(131)\n",
    "ax2 = plt.subplot(lines,cols,2)\n",
    "obj = 'y_test'\n",
    "target_data = eval(obj)[0,:,:,0]\n",
    "value_limit=np.max( target_data ) *0.05 #/ 10\n",
    "# print(obj, \": \", eval(obj).shape, \"\\t\", [eval(obj).min(), eval(obj).max()] )\n",
    "im = plt.imshow(target_data, extent=[0, ss1, ss2,0],vmin=-value_limit, vmax=value_limit, cmap=\"gray\")\n",
    "plt.colorbar(im)\n",
    "# plt.title(\"The elastic z component of VSP data\", fontsize=forts);\n",
    "plt.title(\"target p-wave\", fontsize=forts);\n",
    "plt.xlabel('depth(m)', fontsize=forts);\n",
    "plt.ylabel('time(s)', fontsize=forts);\n",
    "# ax1 = fig.add_subplot(131)\n",
    "ax2.xaxis.set_major_locator(MultipleLocator(75))\n",
    "ax2.xaxis.set(ticklabels=x_libs)#[0,300,600, 900, 1200, 1500]);\n",
    "ax2.yaxis.set(ticklabels=y_libs)#[0,0.4, 0.8, 1.2, 1.6, 2]);\n",
    "plt.setp(ax2.get_xticklabels(), fontsize=10);\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (tf-keras)",
   "language": "python",
   "name": "tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

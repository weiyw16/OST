{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "## headings\n",
    "\"\"\"\n",
    "made by weiyw @ 2019-04-07\n",
    "made to use both three components in segy data\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import struct\n",
    "import segyio\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import (Input, Activation, merge, Dense, Reshape)\n",
    "import metrics as metrics\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters():\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        \n",
    "    def initialize(self, parser):\n",
    "        parser.add_argument('-data_path', required=True, help='path of readin data')\n",
    "        parser.add_argument('-out_name', required=True, help='the name of output model')\n",
    "        parser.add_argument('-nt', type=int, default=4000, help='time steps')\n",
    "        parser.add_argument('-nr', type=int, default=400, help='receivers')\n",
    "        parser.add_argument('-ns', type=int, default=51, help='time steps')\n",
    "        parser.add_argument('-batch_size', type=int, default=2, help='batch size')\n",
    "        parser.add_argument('-nph', type=int, default=2, help='how many phase in one data, 2 for vx vz; 1 for vz')\n",
    "        parser.add_argument('-epoch', type=int, default=100, help='epoch')\n",
    "        parser.add_argument('-ratio', type=float, default=0.5, help='the ratio of training data in the whole dataset')\n",
    "        self.initialized = True\n",
    "        return parser\n",
    "    \n",
    "    def gather_options(self):\n",
    "        if not self.initialized:\n",
    "            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "            parser = self.initialize(parser)\n",
    "        opt, _ = parser.parse_known_args()\n",
    "        self.parser = parser\n",
    "        return parser.parse_args()\n",
    "    \n",
    "    def parse(self):\n",
    "        opt = self.gather_options()\n",
    "        self.opt = opt\n",
    "        return self.opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, data_path, nt, nr, nph):\n",
    "        self.data_path = data_path\n",
    "        self.nt = nt\n",
    "        self.nr = nr\n",
    "        self.nph = nph\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False, ratio=0.5):        \n",
    "        self.n_batches = int( 151 / batch_size * ratio ) #int( len(path) / batch_size * ratio )\n",
    "        x_data = np.empty((batch_size, self.nt, self.nr, self.nph)) ## b-2001-467-4, acc\n",
    "        y_data = np.empty((batch_size, self.nt, self.nr, 1)) ## b-2001-467-1, div, curl\n",
    "        i = 0\n",
    "        with segyio.open(self.data_path,'r',ignore_geometry=True) as segyfile: \n",
    "            segyfile.mmap()\n",
    "            while True:\n",
    "#             for i in range(self.n_batches):\n",
    "                if (i + 1) * batch_size > 151 * ratio:\n",
    "                    i = 0\n",
    "#                     break\n",
    "                for batch_i in range(batch_size):\n",
    "                    for nr_i in range(self.nr):\n",
    "#                     with segyio.open(self.data_path,'r',ignore_geometry=True) as segyfile:      \n",
    "                        y_data[batch_i,:,nr_i,0] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 0]\n",
    "                        x_data[batch_i,:,nr_i,0] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 1]\n",
    "                        x_data[batch_i,:,nr_i,1] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 2]\n",
    "                        x_data[batch_i,:,nr_i,2] = \\\n",
    "                        segyfile.trace[i*batch_size*4*self.nr + batch_i * 4 * self.nr + nr_i * 4 + 3]                 \n",
    "                yield x_data, y_data\n",
    "                i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def simpleNet(nt, nr, nph):\n",
    "    x_input = Input( shape=( nt, nr, nph) )##one_piece\n",
    "    conv1 = Conv2D(\n",
    "        nb_filter=64, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(x_input)\n",
    "    conv1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1)\n",
    "    conv1_1 = Conv2D(\n",
    "        nb_filter=128, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(conv1)\n",
    "    conv1_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_1)\n",
    "    conv1_2 = Conv2D(\n",
    "        nb_filter=128, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(conv1_1)\n",
    "    conv1_2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_2)\n",
    "    conv1_3 = Conv2D(\n",
    "        nb_filter=128, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(conv1_2)\n",
    "    conv1_3 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                               beta_constraint=None, gamma_constraint=None)(conv1_3)\n",
    "    conv2 = Conv2D(\n",
    "        nb_filter=1, nb_row=3, nb_col=3, border_mode=\"same\", data_format=\"channels_last\")(conv1_3)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=conv2)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup\n",
    "opt = parameters().parse()\n",
    "model = simpleNet(opt.nt, opt.nr, opt.nph)\n",
    "model.summary()\n",
    "my_data_loader = Dataloader(opt.data_path, opt.nt, opt.nr, opt.nph)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saveing parameters\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "filepath = os.path.join(save_dir,'{}.best.h5'.format(opt.out_name))\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=0, save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "callbacks = [checkpoint] #, lr_reducer, lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "log = model.fit_generator(my_data_loader.load_batch(batch_size=opt.batch_size, is_testing=False, ratio=opt.ratio),\\\n",
    "              steps_per_epoch=int( (151*opt.ratio-opt.batch_size) /opt.batch_size ), epochs=opt.epoch, verbose=1, callbacks=callbacks, validation_data=None, \\\n",
    "              validation_steps=None, class_weight=None, max_queue_size=10, \\\n",
    "              workers=1, use_multiprocessing=False, shuffle=False, initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving last model\n",
    "json_string = model.to_json()\n",
    "open('model_json', 'w').write(json_string)\n",
    "model.save_weights(os.path.join( save_dir, '{}.final.best.h5'.format(opt.out_name)), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %hist -f simpleNet_training_rawdata_vxvz.py"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (tf-keras)",
   "language": "python",
   "name": "tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
